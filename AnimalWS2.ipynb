{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Animal Web Scraper 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException  # Import TimeoutException\n",
    "import requests\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://www.animalia.bio/philippine-flying-lemur?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-tarsier?endemic=14\n",
      "Scraping: https://www.animalia.bio/visayan-warty-pig?endemic=14\n",
      "Failed to load page: https://www.animalia.bio/visayan-warty-pig?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-crocodile?endemic=14\n",
      "Scraping: https://www.animalia.bio/giant-golden-crowned-flying-fox?endemic=14\n",
      "Scraping: https://www.animalia.bio/luzon-bleeding-heart?endemic=14\n",
      "Scraping: https://www.animalia.bio/tamaraw?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-eagle?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-cobra?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-pangolin?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-forest-turtle?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-deer?endemic=14\n",
      "Scraping: https://www.animalia.bio/visayan-spotted-deer?endemic=14\n",
      "Scraping: https://www.animalia.bio/windowpane-oyster?endemic=14\n",
      "Scraping: https://www.animalia.bio/red-vented-cockatoo?endemic=14\n",
      "Scraping: https://www.animalia.bio/dolabella-auricularia?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-dwarf-kingfisher?endemic=14\n",
      "Scraping: https://www.animalia.bio/palawan-peacock-pheasant?endemic=14\n",
      "Scraping: https://www.animalia.bio/palawan-stink-badger?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-warty-pig?endemic=14\n",
      "Scraping: https://www.animalia.bio/samar-cobra?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-eagle-owl?endemic=14\n",
      "Scraping: https://www.animalia.bio/rufous-hornbill?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-sailfin-lizard?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-hanging-parrot?endemic=14\n",
      "Scraping: https://www.animalia.bio/palawan-bearded-pig?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-pit-viper?endemic=14\n",
      "Scraping: https://www.animalia.bio/palawan-binturong?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-duck?endemic=14\n",
      "Scraping: https://www.animalia.bio/calamian-deer?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-naked-backed-fruit-bat?endemic=14\n",
      "Scraping: https://www.animalia.bio/grays-monitor?endemic=14\n",
      "Scraping: https://www.animalia.bio/waldens-hornbill?endemic=14\n",
      "Scraping: https://www.animalia.bio/northern-luzon-giant-cloud-rat?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-serpent-eagle?endemic=14\n",
      "Scraping: https://www.animalia.bio/mindanao-bleeding-heart?endemic=14\n",
      "Scraping: https://www.animalia.bio/ornate-monitor?endemic=14\n",
      "Scraping: https://www.animalia.bio/sulu-hornbill?endemic=14\n",
      "Scraping: https://www.animalia.bio/mindoro-bleeding-heart?endemic=14\n",
      "Scraping: https://www.animalia.bio/palawan-hornbill?endemic=14\n",
      "Scraping: https://www.animalia.bio/cebu-flowerpecker?endemic=14\n",
      "Scraping: https://www.animalia.bio/philippine-pied-fantail?endemic=14\n",
      "Scraping: https://animalia.bio/philippine-scops-owl\n",
      "Scraping: https://animalia.bio/negros-bleeding-heart-pigeon\n",
      "Scraping: https://animalia.bio/philippine-frogmouth\n",
      "Scraping: https://animalia.bio/philippine-fairy-bluebird\n",
      "Scraping: https://animalia.bio/black-shama\n",
      "Scraping: https://animalia.bio/philippine-coucal\n",
      "Scraping: https://animalia.bio/philippine-trogon\n",
      "Scraping: https://animalia.bio/cinnamon-ibon\n",
      "Scraping: https://animalia.bio/flame-breasted-fruit-dove\n",
      "Scraping: https://animalia.bio/philippine-pygmy-woodpecker\n",
      "Failed to load page: https://animalia.bio/philippine-pygmy-woodpecker\n",
      "Scraping: https://animalia.bio/philippine-magpie-robin\n",
      "Failed to load page: https://animalia.bio/philippine-magpie-robin\n",
      "Scraping: https://animalia.bio/yellow-breasted-fruit-dove\n",
      "Failed to load page: https://animalia.bio/yellow-breasted-fruit-dove\n",
      "Scraping: https://animalia.bio/blue-crowned-racket-tail\n",
      "Failed to load page: https://animalia.bio/blue-crowned-racket-tail\n",
      "Scraping: https://animalia.bio/southern-silvery-kingfisher\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to hold the data\n",
    "animal_names = []\n",
    "animal_types = []\n",
    "animal_descriptions = []\n",
    "animal_population_threats = {}\n",
    "animal_population_stats = {}\n",
    "animal_attributes = {}\n",
    "animal_distributions = {}\n",
    "distributions_p_list = []\n",
    "\n",
    "# Path to your chromedriver executable\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Read the CSV file containing links\n",
    "data = pd.read_csv('AnimalLinkList.csv')\n",
    "# max_scrapes = 5  # Limit the number of pages to scrape\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    # Check if max_scrapes limit has been reached\n",
    "    # if index >= max_scrapes:\n",
    "    #     break\n",
    "\n",
    "    col1_val = row['Links to Scrape']\n",
    "    print(f\"Scraping: {col1_val}\")\n",
    "\n",
    "    # Try to load the page, with error handling for TimeoutException\n",
    "    try:\n",
    "        driver.get(col1_val)\n",
    "    except TimeoutException:\n",
    "        print(f\"Failed to load page: {col1_val}\")\n",
    "        # Append empty strings to all fields and continue to the next link\n",
    "        animal_names.append(\"\")\n",
    "        animal_types.append(\"\")\n",
    "        animal_descriptions.append(\"\")\n",
    "        distributions_p_list.append(\"\")\n",
    "        for key in animal_attributes:\n",
    "            animal_attributes[key].append(\"\")\n",
    "        for key in animal_distributions:\n",
    "            animal_distributions[key].append(\"\")\n",
    "        for key in animal_population_threats:\n",
    "            animal_population_threats[key].append(\"\")\n",
    "        for key in animal_population_stats:\n",
    "            animal_population_stats[key].append(\"\")\n",
    "        continue\n",
    "\n",
    "    # Try to fetch and store each piece of information\n",
    "    try:\n",
    "        input_element = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//span[@class='breadcrumb-link breadcrumb-active']\"))\n",
    "        )  # Animal name\n",
    "        animal_names.append(input_element.text)\n",
    "    except (TimeoutException, NoSuchElementException):\n",
    "        animal_names.append(\"\")\n",
    "\n",
    "    try:\n",
    "        heading = driver.find_element(By.XPATH, \"//p[@class='s-char-heading__name']\")\n",
    "        animal_types.append(heading.text)\n",
    "    except NoSuchElementException:\n",
    "        animal_types.append(\"\")\n",
    "\n",
    "    try:\n",
    "        # Check if the \"show more\" button exists\n",
    "        show_more_button = driver.find_elements(By.XPATH, \"//div[@class='s-char-text']//a[@class='show-more read-more-show']\")\n",
    "        \n",
    "        if show_more_button:\n",
    "            # If the button exists, click it to reveal the full description\n",
    "            show_more_button[0].click()\n",
    "            time.sleep(3)  # Wait for the content to load after clicking \"show more\"\n",
    "        \n",
    "        # Extract the description (whether or not \"show more\" was clicked)\n",
    "        description = driver.find_element(By.XPATH, \"//div[@class='s-char-text']\")\n",
    "        animal_descriptions.append(description.text)\n",
    "        # print(description.text)\n",
    "    except NoSuchElementException:\n",
    "        animal_descriptions.append(\"\")\n",
    "\n",
    "    try:\n",
    "        distributions_cat = driver.find_elements(By.XPATH, \"//div[@class='s-distr-content']//div[@class='s-distr-geography__slug']\")\n",
    "        distributions_name = driver.find_elements(By.XPATH, \"//div[@class='s-distr-content']//a[@class='s-distr-geography__link ']\")\n",
    "        distributions_p = driver.find_element(By.XPATH, \"//div[@class='s-distr-content']//p\")\n",
    "        distributions_p_list.append(distributions_p.text)\n",
    "    except NoSuchElementException:\n",
    "        distributions_p_list.append(\"\")\n",
    "\n",
    "    try:\n",
    "        attributes = driver.find_elements(By.XPATH, \"//div[@class='s-char-kinds__attr']\")\n",
    "        names = driver.find_elements(By.XPATH, \"//a[@class='s-char-kinds__name']\")\n",
    "        for attr, name in zip(attributes, names):\n",
    "            if attr.text not in animal_attributes:\n",
    "                animal_attributes[attr.text] = [\"\"] * (len(animal_names) - 1)  # Initialize with empty strings\n",
    "            animal_attributes[attr.text].append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        for key in animal_attributes:\n",
    "            animal_attributes[key].append(\"\")\n",
    "\n",
    "    try:\n",
    "        for cat, name in zip(distributions_cat, distributions_name):\n",
    "            if cat.text not in animal_distributions:\n",
    "                animal_distributions[cat.text] = [\"\"] * (len(animal_names) - 1)\n",
    "            animal_distributions[cat.text].append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        for key in animal_distributions:\n",
    "            animal_distributions[key].append(\"\")\n",
    "\n",
    "    try:\n",
    "        popu_threats = driver.find_elements(By.XPATH, \"//div[@class='s-population-content']//h3[@class='a-h3']\")\n",
    "        popu_p = driver.find_elements(By.XPATH, \"//div[@class='s-population-content']//p\")\n",
    "        popu_trend = driver.find_elements(By.XPATH, \"//div[@class='s-population-link']//div//div//div\")\n",
    "        popu_stats = driver.find_elements(By.XPATH, \"//div[@class='s-population-link']//a\")\n",
    "        for threat, para in zip(popu_threats, popu_p):\n",
    "            if threat.text not in animal_population_threats:\n",
    "                animal_population_threats[threat.text] = [\"\"] * (len(animal_names) - 1)\n",
    "            animal_population_threats[threat.text].append(para.text)\n",
    "        for trends, stats in zip(popu_trend, popu_stats):\n",
    "            if trends.text not in animal_population_stats:\n",
    "                animal_population_stats[trends.text] = [\"\"] * (len(animal_names) - 1)\n",
    "            animal_population_stats[trends.text].append(stats.text)\n",
    "    except NoSuchElementException:\n",
    "        for key in animal_population_threats:\n",
    "            animal_population_threats[key].append(\"\")\n",
    "        for key in animal_population_stats:\n",
    "            animal_population_stats[key].append(\"\")\n",
    "\n",
    "# Ensure all lists have the same length\n",
    "max_len = max(len(animal_names), len(animal_types), len(animal_descriptions))\n",
    "\n",
    "while len(animal_names) < max_len:\n",
    "    animal_names.append(\"\")\n",
    "while len(animal_types) < max_len:\n",
    "    animal_types.append(\"\")\n",
    "while len(animal_descriptions) < max_len:\n",
    "    animal_descriptions.append(\"\")\n",
    "while len(distributions_p_list) < max_len:\n",
    "    distributions_p_list.append(\"\")\n",
    "\n",
    "for key in animal_attributes:\n",
    "    while len(animal_attributes[key]) < max_len:\n",
    "        animal_attributes[key].append(\"\")\n",
    "\n",
    "for key in animal_distributions:\n",
    "    while len(animal_distributions[key]) < max_len:\n",
    "        animal_distributions[key].append(\"\")\n",
    "        \n",
    "for key in animal_population_threats:\n",
    "    while len(animal_population_threats[key]) < max_len:\n",
    "        animal_population_threats[key].append(\"\")\n",
    "\n",
    "for key in animal_population_stats:\n",
    "    while len(animal_population_stats[key]) < max_len:\n",
    "        animal_population_stats[key].append(\"\")\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    \"Animal Name\": animal_names,\n",
    "    \"Animal Type\": animal_types,\n",
    "    \"Description\": animal_descriptions,\n",
    "}\n",
    "\n",
    "# Add dynamic attribute columns\n",
    "data.update(animal_attributes)\n",
    "data.update(animal_distributions)\n",
    "data[\"Distribution Info\"] = distributions_p_list\n",
    "data.update(animal_population_threats)\n",
    "data.update(animal_population_stats)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv(\"animal2.csv\", index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "#If now show more button it will just directly print the description, \n",
    "#Because the code can't get the description if the show more button is not present it will just directly just skip the description in result of this absence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print\n",
    "        # print(input_element.text +\" - \"+ heading.text)#print the animal name\n",
    "        # # Append data to lists\n",
    "        # animal_names.append(input_element.text)\n",
    "        # animal_types.append(heading.text)\n",
    "        # #print the animal attributes \n",
    "        # for attr, name in zip(attributes, names):\n",
    "        #     print(attr.text+\" - \"+name.text)\n",
    "        #     animal_attributes.append(attr.text + \" - \" + name.text)\n",
    "        # #print the animal description\n",
    "        # print(description.text)\n",
    "        # animal_descriptions.append(description.text)\n",
    "        # #print the animal destribution\n",
    "        # for cat, name in zip(destributions_cat, destributions_name):\n",
    "        #     print(cat.text +\" - \"+ name.text)\n",
    "        #     animal_distributions.append(cat.text + \" - \" + name.text)\n",
    "        # print(destributions_p.text)\n",
    "        # animal_distributions.append(destributions_p.text)\n",
    "        # #population\n",
    "        # for threat, para in zip(popu_threats, popu_p):\n",
    "        #     print(threat.text +\" - \"+ para.text)\n",
    "        #     animal_population_threats.append(threat.text + \" - \" + para.text)\n",
    "        # for trends, stats in zip(popu_trend, popu_stats):\n",
    "        #     print(trends.text +\" - \"+ stats.text)\n",
    "        #     animal_population_stats.append(trends.text + \" - \" + stats.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
